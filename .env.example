# MediTalk Environment Configuration Example

# Hugging Face authentication token
# Get your token from: https://huggingface.co/settings/tokens
# You need to request access to the gated model: https://huggingface.co/canopylabs/orpheus-3b-0.1-ft
HUGGINGFACE_TOKEN=your_huggingface_token_here

# Optional: Override the default Orpheus model
# ORPHEUS_MODEL=canopylabs/orpheus-3b-0.1-ft

# Medical AI Models
# Current: Meditron-7B (text-only)
MEDITRON_MODEL=epfl-llm/meditron-7b # or microsoft/DialoGPT-medium

# MultiMeditron (multimodal - images + text)
# Default model: ClosedMeditron/Mulimeditron-End2End-CLIP-medical (private HF repo)
MULTIMEDITRON_MODEL=ClosedMeditron/Mulimeditron-End2End-CLIP-medical

# MultiMeditron HuggingFace token (for accessing private model)
# Get access to: https://huggingface.co/ClosedMeditron/Mulimeditron-End2End-CLIP-medical
# And to: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct
MULTIMEDITRON_HF_TOKEN=your_multimeditron_token_here

# Base LLM for MultiMeditron tokenizer (optional, default shown below)
# BASE_LLM=meta-llama/Meta-Llama-3.1-8B-Instruct

# Whisper ASR model size: tiny, base, small, medium, large
# tiny: ~39 MB, base: ~74 MB, small: ~244 MB, medium: ~769 MB, large: ~1550 MB
# Using tiny model for maximum stability on CPU
WHISPER_MODEL=tiny

# Service URLs (for local deployment)
ORPHEUS_URL=http://localhost:5005
BARK_URL=http://localhost:5008