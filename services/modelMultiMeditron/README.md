# MultiMeditron Service

Service multimodal pour MediTalk utilisant le mod√®le MultiMeditron du LiGHT lab (EPFL).

## üéØ Capacit√©s

### Actuel (Meditron-7B)
- ‚úì Questions m√©dicales textuelles
- ‚úó Pas de support d'images

### Nouveau (MultiMeditron)
- ‚úì Questions m√©dicales textuelles (compatibilit√© compl√®te)
- ‚úì **Support d'images m√©dicales** (X-rays, CT scans, MRI, etc.)
- ‚úì **Questions multimodales** (texte + image)
- ‚úì Utilisation du token sp√©cial `<|reserved_special_token_0|>`

## üìã Architecture

```
Port 5006: Meditron-7B (existant, inchang√©)
Port 5009: MultiMeditron (nouveau, multimodal)
```

## üõ†Ô∏è Impl√©mentation

Le service suit **exactement** le pattern d'inf√©rence d√©crit dans le [README de MultiMeditron](https://github.com/EPFLiGHT/MultiMeditron):

### Code Pattern (from MultiMeditron README)

```python
# Load model
model = MultiModalModelForCausalLM.from_pretrained("path/to/trained/model")

# Setup collator
collator = DataCollatorForMultimodal(
    tokenizer=tokenizer,
    tokenizer_type="llama",
    modality_processors=model.processors(),
    modality_loaders={"image": loader},
    attachment_token_idx=attachment_token_idx,
    add_generation_prompt=True
)

# Create sample
sample = {
    "conversations": [{"role": "user", "content": question}],
    "modalities": [{"type": "image", "value": "path/to/image"}]
}

# Generate
batch = collator([sample])
outputs = model.generate(batch=batch, temperature=0.1)
response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]
```

### Notre Impl√©mentation

Le fichier `app.py` impl√©mente ce pattern dans la fonction `generate_multimeditron_response()`.

## üöÄ Configuration

### Variables d'Environnement

Ajoutez dans `.env`:

```bash
# Base LLM model (tokenizer source)
BASE_LLM=meta-llama/Meta-Llama-3.1-8B-Instruct

# Trained MultiMeditron model path
MULTIMEDITRON_MODEL=/path/to/trained/multimeditron/model
```

### Mode Fallback

Si `MULTIMEDITRON_MODEL` n'est pas configur√©, le service fonctionne en **mode fallback** :
- ‚úì Le service d√©marre
- ‚úì Les endpoints r√©pondent
- ‚ö†Ô∏è R√©ponses placeholder au lieu de vraies inf√©rences
- ‚Üí Permet de tester l'architecture sans mod√®le

## üì° API Endpoints

### 1. `/health` - Health Check
```bash
curl http://localhost:5009/health
```

R√©ponse:
```json
{
  "status": "partial|ready|not_ready",
  "service": "MultiMeditron Medical AI",
  "model_loaded": true,
  "tokenizer_loaded": true,
  "note": "..."
}
```

### 2. `/ask` - Questions textuelles (compatible Meditron)
```bash
curl -X POST "http://localhost:5009/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is hypertension?",
    "max_length": 512,
    "temperature": 0.7,
    "generate_audio": true,
    "voice": "tara"
  }'
```

### 3. `/ask_multimodal` - Questions multimodales (NOUVEAU!)
```bash
curl -X POST "http://localhost:5009/ask_multimodal" \
  -F "question=What abnormalities do you see in this chest X-ray?" \
  -F "image=@/path/to/xray.jpg" \
  -F "max_length=512" \
  -F "temperature=0.7" \
  -F "generate_audio=true" \
  -F "voice=tara"
```

## Installation

### Automatique (recommand√©)
```bash
cd /mloscratch/users/teissier/MediTalk
./setup-multimeditron.sh
```

### Manuel

1. **Cr√©er l'environnement virtuel:**
```bash
cd services/modelMultiMeditron
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

2. **Installer MultiMeditron:**
```bash
# Option A: Cloner dans le service (recommand√©)
git clone https://github.com/epflight/MultiMeditron.git multimeditron
pip install -e ./multimeditron

# Option B: Installer depuis GitHub
pip install git+https://github.com/epflight/MultiMeditron.git
```

3. **Configurer le mod√®le dans `.env`:**
```bash
MULTIMEDITRON_MODEL=/path/to/your/trained/model
```

## Structure du service

```
services/modelMultiMeditron/
‚îú‚îÄ‚îÄ app.py                    # Service FastAPI
‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                 # Ce fichier
‚îú‚îÄ‚îÄ venv/                     # Virtual environment (gitignored)
‚îî‚îÄ‚îÄ multimeditron/           # Code MultiMeditron (gitignored)
    ‚îî‚îÄ‚îÄ src/
        ‚îî‚îÄ‚îÄ multimeditron/
            ‚îú‚îÄ‚îÄ model/
            ‚îú‚îÄ‚îÄ train/
            ‚îî‚îÄ‚îÄ ...
```

## D√©marrage

### Mode Test (MultiMeditron seul)
```bash
cd services/modelMultiMeditron
source venv/bin/activate
python app.py
```

Le service d√©marrera sur `http://localhost:5009`

### Mode Production (tous les services)
```bash
./start-with-multimeditron.sh
```

D√©marre:
- Meditron-7B sur port 5006 (backup)
- MultiMeditron sur port 5009 (nouveau)
- Tous les autres services

## Configuration

### Variables d'environnement (`.env`)

```bash
# Requis
HUGGINGFACE_TOKEN=your_token_here

# MultiMeditron
MULTIMEDITRON_MODEL=/path/to/model  # Optionnel, fallback si vide

# Autres (inchang√©s)
MEDITRON_MODEL=epfl-llm/meditron-7b
ORPHEUS_MODEL=canopylabs/orpheus-3b-0.1-ft
WHISPER_MODEL=tiny
```

## Modes de fonctionnement

### 1. Mode Fallback (pas de mod√®le configur√©)
- Service d√©marre sans erreur
- R√©pond avec des messages placeholder
- Utile pour tester l'infrastructure

### 2. Mode Partial (tokenizer charg√©, mod√®le non charg√©)
- Tokenizer MultiMeditron fonctionnel
- G√©n√©ration pas encore impl√©ment√©e
- Permet de tester l'API

### 3. Mode Full (tout charg√©)
- Mod√®le MultiMeditron complet
- G√©n√©ration multimodale fonctionnelle
- Mode production

## D√©veloppement

### Structure du code

```python
# Chargement du mod√®le
from multimeditron.model.model import MultiModalModelForCausalLM

model = MultiModalModelForCausalLM.from_pretrained(
    model_path,
    dtype=torch.bfloat16,
    use_safetensors=True
).to(device)

# Utilisation du token sp√©cial
ATTACHMENT_TOKEN = "<|reserved_special_token_0|>"
```

### Points d'extension

1. **`startup_event()`**: Charger le mod√®le
2. **`ask_question()`**: G√©n√©ration text-only
3. **`ask_multimodal_question()`**: G√©n√©ration multimodale
4. **`generate_fallback_response()`**: R√©ponses de fallback

## Tests

### 1. Test de sant√©
```bash
curl http://localhost:5009/health | jq
```

### 2. Test text-only
```bash
curl -X POST "http://localhost:5009/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is diabetes?", "generate_audio": false}' | jq
```

### 3. Test multimodal
```bash
# T√©l√©charger une image de test
wget https://example.com/chest_xray.jpg -O test_xray.jpg

# Envoyer la requ√™te
curl -X POST "http://localhost:5009/ask_multimodal" \
  -F "question=Describe this X-ray" \
  -F "image=@test_xray.jpg" \
  -F "generate_audio=false" | jq
```

## Troubleshooting

### Service ne d√©marre pas
```bash
# V√©rifier les logs
tail -f ../../logs/modelMultiMeditron.log

# V√©rifier l'environnement virtuel
source venv/bin/activate
python -c "import torch; print(torch.__version__)"
```

### Mod√®le ne charge pas
```bash
# V√©rifier le chemin
echo $MULTIMEDITRON_MODEL
ls -la $MULTIMEDITRON_MODEL

# V√©rifier la RAM/GPU
nvidia-smi  # Si GPU
free -h     # RAM
```

### Import errors
```bash
# R√©installer MultiMeditron
source venv/bin/activate
pip uninstall multimeditron
pip install git+https://github.com/epflight/MultiMeditron.git
```

## Migration depuis Meditron-7B

Le service MultiMeditron est **100% compatible** avec l'API Meditron existante via l'endpoint `/ask`.

Pour migrer progressivement:

1. **Phase 1**: Garder les deux (5006 et 5009)
2. **Phase 2**: Router certaines requ√™tes vers MultiMeditron
3. **Phase 3**: Utiliser MultiMeditron par d√©faut, Meditron en backup
4. **Phase 4**: Remplacer compl√®tement (optionnel)

## Rollback

Si probl√®me avec MultiMeditron:

```bash
# Arr√™ter tous les services
./stop-local.sh

# Red√©marrer sans MultiMeditron
./start-local.sh

# Meditron-7B continue sur port 5006 (aucun impact)
```

## R√©f√©rences

- [MultiMeditron Repository](https://github.com/epflight/MultiMeditron)
- [Guide d'int√©gration](../../MULTIMEDITRON-INTEGRATION.md)
- [Documentation MediTalk](../../README.md)
